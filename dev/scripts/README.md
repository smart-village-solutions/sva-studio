# Monitoring Stack Scripte

Dieses Verzeichnis enth√§lt Backup/Restore und Maintenance-Scripte f√ºr den Monitoring Stack.

## üìã Verf√ºgbare Scripte

### üîÑ Backup & Restore

#### `backup-monitoring.sh`
Erstellt einen vollst√§ndigen Snapshot des Monitoring Stacks.

**Features:**
- Prometheus TSDB Snapshot via Admin API
- Loki BoltDB Index + Chunks
- AlertManager Daten
- SHA256 Checksums f√ºr Integrit√§t
- Automatische Rotation (> 30 Tage)

**Usage:**
```bash
# Manuelles Backup
./dev/scripts/backup-monitoring.sh

# Mit custom Backup-Verzeichnis
BACKUP_DIR=/mnt/backups ./dev/scripts/backup-monitoring.sh

# T√§gliches Backup via Cron (02:00 UTC)
0 2 * * * /path/to/sva-studio/dev/scripts/backup-monitoring.sh >> /var/log/sva-backup.log 2>&1
```

**Output:**
```
./backups/
‚îî‚îÄ‚îÄ monitoring-backup-20260208_120000/
    ‚îú‚îÄ‚îÄ prometheus-snapshot.tar.gz
    ‚îú‚îÄ‚îÄ prometheus-snapshot.tar.gz.sha256
    ‚îú‚îÄ‚îÄ loki-data.tar.gz
    ‚îú‚îÄ‚îÄ loki-data.tar.gz.sha256
    ‚îú‚îÄ‚îÄ alertmanager-data.tar.gz
    ‚îú‚îÄ‚îÄ alertmanager-data.tar.gz.sha256
    ‚îî‚îÄ‚îÄ backup-metadata.json
```

---

#### `restore-monitoring.sh`
Stellt den Monitoring Stack aus einem Backup wieder her.

**‚ö†Ô∏è WARNUNG:** L√∂scht aktuelle Daten! Backup zuerst!

**Usage:**
```bash
# Restore von lokalem Backup
./dev/scripts/restore-monitoring.sh ./backups/monitoring-backup-20260208_120000

# Restore von S3 (TODO: nicht implementiert)
# aws s3 cp s3://sva-backups/monitoring-backup-20260208_120000 ./backups/ --recursive
# ./dev/scripts/restore-monitoring.sh ./backups/monitoring-backup-20260208_120000
```

**Schritte:**
1. Stoppt Monitoring Stack (`docker compose down`)
2. L√∂scht alte Volumes
3. Validiert Checksums
4. Entpackt Backups in neue Volumes
5. Startet Stack neu
6. F√ºhrt Health Checks durch

---

## üöÄ Quick Start

### Erstes Backup erstellen
```bash
# 1. Monitoring Stack sollte laufen
docker compose -f docker-compose.monitoring.yml ps

# 2. Backup erstellen
./dev/scripts/backup-monitoring.sh

# 3. Backup-Verzeichnis pr√ºfen
ls -lh backups/
```

### Restore testen
```bash
# 1. Testdaten generieren (optional)
# ... (Prometheus Metriken sammeln lassen)

# 2. Backup erstellen
./dev/scripts/backup-monitoring.sh

# 3. Restore durchf√ºhren
./dev/scripts/restore-monitoring.sh ./backups/monitoring-backup-YYYYMMDD_HHMMSS

# 4. Verifizieren
open http://localhost:3001  # Grafana
```

---

## üìä Monitoring der Backups

### Backup-Status via Prometheus

**TODO:** Pushgateway Integration (siehe docs/staging/2026-02/staging-todos.md)

Aktuell: Manuell via Logs pr√ºfen
```bash
# Letztes Backup-Log
tail -100 /var/log/sva-backup.log

# Backup-Gr√∂√üe
du -sh backups/
```

### Alerts bei fehlgeschlagenen Backups

**TODO:** Alert-Rule hinzuf√ºgen (siehe docs/staging/2026-02/staging-todos.md)

---

## üîß Troubleshooting

### Backup schl√§gt fehl: "Prometheus Snapshot failed"

**Ursache:** Admin API nicht aktiviert

**L√∂sung:**
```yaml
# docker-compose.monitoring.yml
prometheus:
  command:
    - "--web.enable-admin-api"  # ‚Üê muss gesetzt sein
```

Neu starten:
```bash
docker compose -f docker-compose.monitoring.yml restart prometheus
```

---

### Restore schl√§gt fehl: "Checksum mismatch"

**Ursache:** Backup korrumpiert

**L√∂sung:**
1. Anderen Backup versuchen
2. Checksum manuell pr√ºfen:
   ```bash
   cd backups/monitoring-backup-YYYYMMDD_HHMMSS
   sha256sum -c prometheus-snapshot.tar.gz.sha256
   ```
3. Falls alle Backups korrumpiert: Neu anfangen (Datenverlust)

---

### Container startet nach Restore nicht

**Debugging:**
```bash
# Logs pr√ºfen
docker logs sva-studio-prometheus

# Volume-Inhalt pr√ºfen
docker run --rm -v sva-studio_prometheus-data:/prometheus alpine ls -la /prometheus

# Permissions fixen
docker run --rm -v sva-studio_prometheus-data:/prometheus alpine chown -R 65534:65534 /prometheus
```

---

## üìÅ Backup-Retention

**Standard:** 30 Tage (automatisch gel√∂scht)

**Custom Retention:**
```bash
# In backup-monitoring.sh Zeile 102 anpassen:
find "${BACKUP_DIR}" -maxdepth 1 -type d -name "monitoring-backup-*" -mtime +90 -exec rm -rf {} \;
#                                                                              ^^^ Tage
```

---

## üîê Security Best Practices

1. **Backups verschl√ºsseln** (f√ºr Production):
   ```bash
   # GPG-Verschl√ºsselung
   tar -czf - "${BACKUP_PATH}" | gpg --encrypt --recipient ops@sva-studio.de > backup.tar.gz.gpg
   ```

2. **S3 Server-Side Encryption**:
   ```bash
   aws s3 cp backup.tar.gz s3://bucket/ --sse AES256
   ```

3. **Access Control**:
   ```bash
   chmod 700 dev/scripts/*.sh
   chown root:root dev/scripts/*.sh
   ```

---

## ‚è±Ô∏è Performance

### Backup-Zeiten (Durchschnitt)

| Service | Datenmenge | Dauer |
|---------|------------|-------|
| Prometheus (7d) | 500MB‚Äì2GB | 30‚Äì60s |
| Loki (7d) | 200MB‚Äì1GB | 20‚Äì40s |
| AlertManager | < 10MB | 5s |
| **Total** | **1‚Äì3GB** | **~2 Min** |

### Restore-Zeiten

| Service | Dauer |
|---------|-------|
| Volumes l√∂schen | 5‚Äì10s |
| Entpacken | 30‚Äì90s |
| Container Start | 10‚Äì20s |
| Health Checks | 10‚Äì20s |
| **Total** | **~2 Min** |

---

## üéØ N√§chste Schritte

Siehe [docs/staging/2026-02/staging-todos.md](../../docs/staging/2026-02/staging-todos.md):

- [ ] S3/MinIO Integration
- [ ] Automatisierte Cron-Jobs
- [ ] Backup Monitoring (Prometheus Metric)
- [ ] W√∂chentliche Restore-Tests
- [ ] Slack Notifications bei Backup-Fehlern

---

**Erstellt:** 2026-02-08
**Getestet:** ‚úÖ Lokal (macOS, Docker Desktop)
**Production-ready:** ‚è≥ Nach S3-Integration
