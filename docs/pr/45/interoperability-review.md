# PR #45 Interoperability & Data Portability Review

**Reviewer Role:** Interoperability & Data Reviewer
**Review Date:** 8. Februar 2026
**Status:** üü° CONDITIONAL APPROVAL (Risiken erkannt)
**Branch:** feat/logging
**Components:** Observability Stack (OTEL, Prometheus, Loki, Redis Sessions)

---

## Leitfrage: Kann eine Kommune morgen wechseln ‚Äì ohne Datenverlust?

‚ö†Ô∏è **ANTWORT:** Teilweise ja, aber mit kritischen L√ºcken.

---

## INTEROPERABILIT√ÑT-BEWERTUNG: **Mittel**

Die Observability-Architektur ist **stark auf offene Standards gebaut** (OTLP, Prometheus, Loki), aber **wesentliche Export- und Migrations-F√§higkeiten fehlen**.

---

## ‚úÖ St√§rken

### 1. **Offene Datenprotokolle (OTLP v1)**
- **OTLP HTTP Endpoints:** `http://collector:4318/v1/metrics` und `v1/logs`
- **Standardisiert:** OpenTelemetry Protocol ist ein CNCF-Standard, nicht propriet√§r
- **Vorteil:** Beliebiger OTLP-kompatibler Exporter kann andocken
- **Code:** [packages/monitoring-client/src/otel.ts#L127-L131](../packages/monitoring-client/src/otel.ts#L127-L131)

### 2. **Prometheus Metrics Format (PromQL & Export)**
- **Scrape Endpoints:** Prometheus scrapet Standard `/metrics` auf Port 8889 von OTEL Collector
- **Format:** OpenMetrics/Prometheus (IETF-Standard)
- **Export:** `GET /api/v1/query_range` liefert exportierbare Time-Series
- **Vorteil:** Kann zu VictoriaMetrics, Thanos, InfluxDB etc. migriert werden
- **Retention:** 7 Tage (konfigurierbar in [docker-compose.monitoring.yml#L15](../docker-compose.monitoring.yml#L15))

### 3. **Loki Logs (LogQL Export)**
- **Endpoint:** `http://loki:3100/loki/api/v1/push` (OTLP Import)
- **Query API:** `GET /loki/api/v1/query_range` zur Datenextraktion
- **Retention:** 168h (7 Tage) mit `delete_request_store` f√ºr GDPR-L√∂schungen
- **Schema:** `v12` versioniert in [dev/monitoring/loki/loki-config.yml#L23-L27](../dev/monitoring/loki/loki-config.yml#L23-L27)

### 4. **Workspace-Isolation durch Context**
- **Mandatory Label:** Alle Logs/Metriken haben `workspace_id` Tag
- **AsyncLocalStorage:** Request-Context wird per Middleware injiziert ([packages/sdk/src/observability/context.ts#L48-L73](../packages/sdk/src/observability/context.ts#L48-L73))
- **Vorteil:** Vollst√§ndige Datentrennung m√∂glich via `{workspace_id="org-123"}` Filterung

### 5. **PII-Redaction (mehrstufig)**
- **Level 1:** OTEL SDK redacted Forbidden Labels (user_id, email, token, ip) ‚Üí nur Whitelist bleibt
- **Level 2:** Promtail redacted nochmal via Regex (`relabel_configs` in [dev/monitoring/promtail/promtail-config.yml#L29-L33](../dev/monitoring/promtail/promtail-config.yml#L29-L33))
- **Level 3:** Email-Masking (`john.doe@example.com` ‚Üí `j***@example.com`)
- **Dokumentation:** [docs/development/observability-best-practices.md#L46-L100](../docs/development/observability-best-practices.md#L46-L100)

### 6. **Session API mit Versionskontrolle**
- **Struktur:** `SessionData` ist typsicher mit Validierung ([packages/auth/src/redis-session.ts#L4-L8](../packages/auth/src/redis-session.ts#L4-L8))
- **Serialisierung:** JSON (portabel)
- **TTL:** 7 Tage (consistent mit Logs/Metriken)

---

## ‚ö†Ô∏è Interoperabilit√§ts-Risiken

### üî¥ KRITISCH: Keine Prometheus Export-API

**Problem:**
Es gibt **keine Exportier-API/Tools**, um alle Metriken aus Prometheus zu exportieren.

```
HEUTE: Prometheus ‚Üí via /api/v1/query_range manuell querybar
FEHLT: Prometheus ‚Üí Standard-Format (OpenMetrics JSON, protobuf, etc.)
```

**Auswirkung:**
- ‚ùå Keine vollst√§ndige Metrik-Migration in andere Zeit-Reihen-Datenbanken
- ‚ùå Bei Prometheus-Cluster-Migration k√∂nnten Daten verloren gehen
- ‚ùå Keine Point-in-Time Recovery f√ºr Metriken

**Behebung erforderlich:**
```bash
# Sollte m√∂glich sein (ist es aber nicht dokumentiert/implementiert):
prometheus-admin export --output=json --workspace_id=org-123 > metrics.json
prometheus-admin export --output=openmetrics > metrics.txt
```

---

### üî¥ KRITISCH: Keine Loki Bulk-Export-Funktion

**Problem:**
Loki hat **keine nativen Bulk-Export-APIs** f√ºr Logs.

```
HEUTE: LogQL Queries, aber nur mit Limit/Pagination
FEHLT: Batch-Export, Streaming-Export f√ºr gro√üe Mengen
```

**Auswirkung:**
- ‚ùå Logs > 10GB lassen sich nicht vollst√§ndig exportieren
- ‚ùå Migration zu ELK/Datadog/Splunk schwierig
- ‚ùå GDPR-Recht auf Datenportabilit√§t fraglich f√ºr gro√üe Workspaces

**Workaround (suboptimal):**
```bash
# Nur via LogQL Query Loop m√∂glich:
curl 'http://loki:3100/loki/api/v1/query_range?query={workspace_id="org-123"}&start=X&end=Y'
```

**Behebung erforderlich:**
```typescript
// loki/export.ts ‚Äì NICHT VORHANDEN
export async function exportWorkspaceLogs(
  workspaceId: string,
  format: 'jsonl' | 'logfmt'
): Promise<AsyncIterable<string>> {
  // Stream alle Logs in beliebige Gr√∂√üe
}
```

---

### üü° MITTEL: Session-API hat keine Versioning-Strategie

**Problem:**
`SessionData` Interface k√∂nnte Breaking Changes bekommen ohne Migrations-Path.

```typescript
// HEUTE: SessionData ist nicht versioniert
export interface SessionData {
  userId: string;
  workspaceId: string;
  createdAt: number;
  expiresAt: number;
  metadata?: Record<string, unknown>; // Catch-all, aber nicht versioned
}

// BESSER: Explizite Versionierung
export interface SessionDataV1 {
  _version: 1;
  userId: string;
  // ...
}
```

**Auswirkung:**
- üü° Wenn neues Field hinzugef√ºgt wird ‚Üí alte Sessions brechen
- üü° Keine Migration-Strategie f√ºr Redis-Keys

**Behebung:**
```typescript
// Migrations-Handler FEHLT:
function migrateSessionV0ToV1(data: unknown): SessionDataV1 {
  // H√§tte sein sollen
}
```

---

### üü° MITTEL: OTEL SDK hat keine Deprecation-Pfade

**Problem:**
`OtelConfig` Interface k√∂nnte Backwards-Compatibility brechen.

```typescript
export interface OtelConfig {
  serviceName: string;
  environment?: string;
  otlpEndpoint?: string;  // ‚Üê Wenn dies mal √§ndert ‚Üí Breaking
  logLevel?: DiagLogLevel;
}
```

**Fehlt:**
- ‚ùå Version der Config-API dokumentiert
- ‚ùå Deprecation-Pfade f√ºr alte Parameter
- ‚ùå Migration-Guide wenn API sich √§ndert

**Best Practice w√§re:**
```typescript
export interface OtelConfig {
  serviceName: string;
  environment?: string;
  // Deprecation: otlpEndpoint renamed to collectors.otlp.http.endpoint
  otlpEndpoint?: string; /** @deprecated use collectors instead */
  collectors?: { otlp?: { http?: { endpoint?: string } } };
}
```

---

## üîÑ Export-/Import-F√§higkeiten

| Datentyp | Export | Import | Format | Status | Notes |
|----------|--------|--------|--------|--------|-------|
| **Prometheus Metriken** | ‚ö†Ô∏è Teilweise | ‚ùå Nein | PromQL Text | üü° Manual | Via `/query_range` querybar, aber kein bulk-export |
| **Loki Logs** | ‚ö†Ô∏è Teilweise | ‚ùå Nein | JSON via API | üü° Pagination | Nur small batches mit LogQL |
| **Redis Sessions** | ‚ùå Nein | ‚ùå Nein | JSON (internal) | üî¥ Kritisch | Keine Backup-Strategie, keine Migration |
| **Business Events Counter** | ‚úÖ Ja | ‚ö†Ô∏è Teilweise | Prometheus Metrics | üü¢ Gut | Via Prometheus export, keine Reimport-API |
| **Dashboards (Grafana)** | ‚úÖ Ja | ‚úÖ Ja | JSON | üü¢ Gut | Versioniert im Repo [dev/monitoring/grafana/dashboards/](../dev/monitoring/grafana/dashboards/) |
| **Alerting-Rules** | ‚ö†Ô∏è Teilweise | ‚ö†Ô∏è Teilweise | YAML (Loki/Prometheus) | üü° Limited | Konfiguriert in YAML, aber keine Versionierung |

---

## üìã Fehlende Standards & APIs

### 1. **Prometheus Remote-Write/Read Standard**
```yaml
# SOLLTE KONFIGURIERT SEIN (ist es nicht):
global:
  remote_write:
    - url: "http://backup-prometheus:9090/api/v1/write"  # ‚Üê FEHLT
      queue_config:
        capacity: 1000000
```

**Warum wichtig?**
- Erm√∂glicht Multi-Prometheus-Setup (High Availability)
- Erlaubt automatische Replizierung f√ºr Migration
- Standard CNCF-Protokoll

---

### 2. **OpenMetrics Exposition Format**
```bash
# HEUTE: Standard Prometheus Text Format
curl http://otel:8889/metrics

# SOLLTE AUCH UNTERST√úTZT SEIN:
curl http://otel:8889/metrics?format=openmetrics
# ‚Üí W√ºrde histograms/summaries besser abbilden
```

---

### 3. **OTLP Metrics Export Endpoint**
```
VORHANDEN: OTLP Receiver (Pull von App)
FEHLT: OTLP Exporter f√ºr andere OTEL Collector (Daisy-chaining)
```

Sollte sein:
```yaml
exporters:
  otlp:
    endpoint: "http://backup-otel-collector:4318"  # ‚Üê FEHLT
```

---

### 4. **Workspace-Level Data Export API**
```typescript
// NICHT VORHANDEN - sollte es aber geben:
GET /api/workspace/:workspaceId/export?format=jsonl&include=logs,metrics,traces
GET /api/workspace/:workspaceId/delete (f√ºr GDPR)
```

---

## üõ£Ô∏è Migration-Roadmap: "Wie w√ºrde ein Ausstieg funktionieren?"

### Szenario 1: Prometheus ‚Üí VictoriaMetrics

```bash
# STATUS: üü° TEILWEISE M√ñGLICH

# Schritt 1: Alte Metriken exportieren (WORKAROUND, nicht ideal)
for i in {1..100}; do
  curl -s 'http://prometheus:9090/api/v1/query_range' \
    --data-urlencode 'query={workspace_id="org-123"}' \
    --data-urlencode 'start='$((NOW - i*3600))'&end='$((NOW - (i-1)*3600))
done | jq '.data.result[]' > metrics.jsonl

# Schritt 2: In VictoriaMetrics via vmctl (EXTERNE TOOL)
vmctl remote-read --source http://prometheus:9090 \
  --destination http://victoria:8428 \
  --query='{workspace_id="org-123"}'

# Problem: ‚ö†Ô∏è Braucht externe Tools, nicht dokumentiert
```

---

### Szenario 2: Loki ‚Üí ELK Stack

```bash
# STATUS: üî¥ PRAKTISCH UNM√ñGLICH (aktuell)

# Loki hat KEINE Native Log-Stream-Export
# Workaround: LogQL ‚Üí Netzwerk-Query ‚Üí Parse ‚Üí Elasticsearch

# Pseudo-Code (w√ºrde man selbst schreiben m√ºssen):
for stream_id in $(loki query '{workspace_id="org-123"}' | jq '.[].stream'); do
  logs=$(loki query '{workspace_id="org-123"}' -n 10000)
  curl -X POST http://elasticsearch/bulk -d $(
    echo "$logs" | jq -c '{index:{_index:"logs"}} + .message'
  )
done

# üî¥ L√úCKE: Keine offizielle Migration gegeben
```

---

### Szenario 3: Redis Sessions ‚Üí PostgreSQL

```bash
# STATUS: üî¥ PRAKTISCH UNM√ñGLICH

# Redis Sessions haben KEINE Export-API
# Einziger Weg: SCAN alle Keys und JSON-Dump (aber Sessions sind TTL-basiert!)

redis-cli --scan --pattern 'session:*' | \
  xargs -I{} redis-cli GET '{}' > sessions.jsonl

# Problem: ‚ö†Ô∏è Sessionen sind ephemer (7 Tage TTL)
#         ‚ö†Ô∏è Keine Backward-Kompatibilit√§t wenn Schema √§ndert
#         ‚ö†Ô∏è Keine Migrations-Strategie f√ºr neue SessionData-Versionen
```

---

## 7Ô∏è‚É£ Workspace-spezifische Datenportabilit√§t (GDPR)

### ‚úÖ Was funktioniert

```bash
# Logs f√ºr Workspace exportieren (theoretisch)
curl 'http://loki:3100/loki/api/v1/query_range?query={workspace_id="org-123"}'

# Metriken f√ºr Workspace filtern
curl 'http://prometheus:9090/api/v1/query?query=sva_business_events_total{workspace_id="org-123"}'
```

### ‚ùå Was nicht funktioniert

- **Bulk-Export:** Kein Tool f√ºr "exportiere ALLES f√ºr org-123"
- **Streaming:** Logs > 10GB k√∂nnen nicht on-the-fly gestreamt werden
- **Punkt-in-Zeit:** Keine Snapshots f√ºr Compliance-Audits
- **L√∂sch-API:** Loki hat `delete_request_store` aber **keine Public-API daf√ºr**

```typescript
// SOLLTE EXISTIEREN - existiert aber nicht:
POST /api/workspace/:workspaceId/gdpr/export { format: 'jsonl' }
‚Üí Streamed JSONL mit allen Logs/Metriken/Sessions

DELETE /api/workspace/:workspaceId/gdpr/purge
‚Üí L√∂scht ALLE Daten (braucht Approvals)
```

---

## üìä Zusammenfassung: Offene Standards vs. Lock-In

| Standard | Adoption | Status |
|----------|----------|--------|
| **OTLP (OpenTelemetry Protocol)** | ‚úÖ Vollst√§ndig | v1 HTTP + gRPC |
| **Prometheus Format** | ‚úÖ Vollst√§ndig | OpenMetrics compatible |
| **LogQL (Grafana Loki)** | ‚úÖ Vollst√§ndig | Standard Query Language |
| **Redis Protocol** | ‚úÖ Redis-Standard | Aber kein Export-Format definiert |
| **JSON Serialization** | ‚úÖ √úberall | Sessions, Logs, Metriken |
| **OpenMetrics Export** | ‚ö†Ô∏è Implementiert | Aber nicht genutzt |
| **gRPC OTLP** | ‚ö†Ô∏è Supported | Aber nur HTTP wird getestet |
| **Prometheus Remote-Write** | ‚ùå FEHLT | Keine HA/Replication |
| **Workspace-Data Export API** | ‚ùå FEHLT | GDPR-Risiko |
| **Session-Versioning** | ‚ùå FEHLT | Breaking-Change-Risiko |

---

## GESAMTBEWERTUNG: **Gering-Mittel Vendor Lock-In** üü°

### Positiv
- ‚úÖ OTLP ist offen & standardisiert
- ‚úÖ Prometheus ist Industry Standard f√ºr Metriken
- ‚úÖ Loki ist Open Source mit offenen APIs
- ‚úÖ Session-Format (JSON) ist portabel

### Risiken
- ‚ö†Ô∏è **Keine Prometheus Bulk-Export-API** ‚Üí Metriken-Migration schwierig
- ‚ö†Ô∏è **Keine Loki Bulk-Export-API** ‚Üí Log-Migration unm√∂glich bei gro√üen Mengen
- ‚ö†Ô∏è **Keine Session-Versioning** ‚Üí Zuk√ºnftige Breaking Changes
- ‚ö†Ô∏è **Keine Workspace-Export-API** ‚Üí GDPR-Compliance fraglich
- ‚ö†Ô∏è **Keine Migration-Scripts** ‚Üí Kommune bleibt abh√§ngig von SVA

### Konklusion: Kann eine Kommune morgen wechseln?

| Szenario | Status | Aufwand |
|----------|--------|---------|
| **Nur zur neuen OTEL-Instance migrieren** | ‚úÖ M√∂glich | Mittel (OTLP forwarding) |
| **Prometheus zu VictoriaMetrics migrieren** | ‚ö†Ô∏è Mit Workaround | Hoch (manuelle Scripts n√∂tig) |
| **Loki zu ELK migrieren** | ‚ùå Praktisch unm√∂glich | Sehr hoch (Edge-Case Handling) |
| **Sessions migrieren** | ‚ö†Ô∏è M√∂glich mit Redis SCAN | Mittel (aber Datenverlust-Risk) |
| **Kompletter Workspace-Export (GDPR)** | ‚ùå Nicht vorgesehen | Sehr hoch (Custom Code) |

---

## üéØ EMPFEHLUNGEN (Priorit√§t)

### P0 (Kritisch ‚Äì vor Merge)
- [ ] **Workspace-Level Export-API implementieren** (GDPR-Risiko)
  ```typescript
  GET /api/workspace/:id/export { format: 'jsonl', include: ['logs', 'metrics'] }
  ```

- [ ] **Prometheus Remote-Write konfigurieren** (HA-Vorbereitung)
  ```yaml
  global:
    remote_write:
      - url: http://backup-prometheus:9090/api/v1/write
  ```

- [ ] **Session-Versioning hinzuf√ºgen**
  ```typescript
  export interface SessionDataV1 {
    _version: 1;
    userId: string;
    // ...
  }
  ```

### P1 (Hoch ‚Äì n√§chstes Release)
- [ ] **Prometheus Metrics Backup-Script** (prometheus-admin cli)
- [ ] **Loki Log Streaming-Export** (f√ºr gro√üe Workspaces)
- [ ] **Migration-Dokumentation** schreiben (Prometheus ‚Üí VictoriaMetrics, Loki ‚Üí ELK)
- [ ] **GDPR-L√∂sch-API implementieren** (Public endpoint f√ºr `delete_request_store`)

### P2 (Mittel ‚Äì mittelfristig)
- [ ] OpenMetrics Exposition Format aktivieren
- [ ] gRPC OTLP Tests hinzuf√ºgen
- [ ] API-Versionierung dokumentieren (v1, v2 mit Deprecation-Pfaden)

---

## Sign-off

**Reviewer:** Interoperability & Data Reviewer
**Date:** 8. Februar 2026

**Status:** üü° **CONDITIONAL APPROVAL**

### Bedingungen:
1. ‚úÖ **OTLP-Integration ist gut** ‚Äì kann so mergen
2. ‚ö†Ô∏è **Aber Workspace-Export-API ist CRITICAL** ‚Äì muss vor Production-Release kommen
3. ‚ö†Ô∏è **Session-Versioning sollte hinzugef√ºgt werden** ‚Äì vor gro√üer √Ñnderung
4. ‚ö†Ô∏è **Migration-Doku fehlt vollst√§ndig** ‚Äì muss sp√§ter erg√§nzt werden

### Begr√ºndung:
Die Architektur ist grunds√§tzlich **offen und portabel**, aber es fehlen **praktische Migrations-APIs** f√ºr Datenexporte. Eine Kommune k√∂nnte technisch wechseln, br√§uchte aber custom Code oder externe Tools ‚Äì das ist nicht ideal f√ºr Vendor-Lock-In-Freiheit.
